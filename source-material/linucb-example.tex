\subsection{Example: News Article Recommendation}

The LinUCB algorithm applies to contexts where each arm's reward depends on side information (the \emph{context}) observed before each decision. We trace LinUCB through six rounds of a news article recommendation task.

\textbf{Setup:} A website recommends articles to users. There are two user types (contexts): ``tech-interested'' (T) and ``sports-interested'' (S), and three articles (arms): Tech article, Sports article, and General article. Each context--arm pair is represented by a 2-dimensional feature vector $\boldsymbol{\phi}(x, a) \in \mathbb{R}^2$:

\begin{center}
\begin{tabular}{lll}
  User & Article & Feature vector $\boldsymbol{\phi}$ \\
  \hline
  Tech (T) & Tech article & $[1.0,\; 0.0]$ \\
  Tech (T) & Sports article & $[0.0,\; 0.5]$ \\
  Tech (T) & General article & $[0.5,\; 0.5]$ \\
  Sports (S) & Tech article & $[0.0,\; 0.5]$ \\
  Sports (S) & Sports article & $[1.0,\; 0.0]$ \\
  Sports (S) & General article & $[0.5,\; 0.5]$ \\
\end{tabular}
\end{center}

The reward function is linear in these features: $r(x, a) = \boldsymbol{\theta}^* \cdot \boldsymbol{\phi}(x, a) + \varepsilon$, where $\boldsymbol{\theta}^* = [0.8,\; 0.4]$ is the true (unknown) parameter vector and $\varepsilon$ is zero-mean noise. The expected rewards are therefore:
\begin{itemize}
  \item Tech user: Tech article yields $0.8$, Sports article yields $0.2$, General article yields $0.6$.
  \item Sports user: Tech article yields $0.2$, Sports article yields $0.8$, General article yields $0.6$.
\end{itemize}

The optimal policy is to recommend Tech articles to Tech users and Sports articles to Sports users. The General article is suboptimal for both but still better than the mismatched articles.

LinUCB maintains a ridge-regression estimate $\hat{\boldsymbol{\theta}}_t$ of $\boldsymbol{\theta}^*$, updated after each observation. The algorithm uses hyperparameters $\lambda = 1.0$ (ridge regularization) and $\alpha = 1.0$ (exploration bonus).

\textbf{Initialization ($t = 0$):} Set $\mathbf{V}_0 = \lambda \mathbf{I} = \mathbf{I}$ (the $2 \times 2$ identity matrix) and $\mathbf{b}_0 = \mathbf{0}$. The initial parameter estimate is $\hat{\boldsymbol{\theta}}_0 = \mathbf{V}_0^{-1} \mathbf{b}_0 = \mathbf{0}$.

\textbf{Round 1:} A Tech user arrives (context $x_1 = \text{T}$). For each article $a$, compute the upper confidence bound:
\begin{equation*}
  \text{UCB}_t(a) = \hat{\boldsymbol{\theta}}_{t-1} \cdot \boldsymbol{\phi}(x_t, a) + \alpha \sqrt{\boldsymbol{\phi}(x_t, a)^\top \mathbf{V}_{t-1}^{-1} \boldsymbol{\phi}(x_t, a)}.
\end{equation*}

With $\hat{\boldsymbol{\theta}}_0 = [0, 0]$ and $\mathbf{V}_0^{-1} = \mathbf{I}$:
\begin{align*}
  \text{UCB}_1(\text{Tech}) &= 0 + 1.0 \cdot \sqrt{[1, 0] \cdot [1, 0]} = 1.0, \\
  \text{UCB}_1(\text{Sports}) &= 0 + 1.0 \cdot \sqrt{[0, 0.5] \cdot [0, 0.5]} = 0.5, \\
  \text{UCB}_1(\text{Gen}) &= 0 + 1.0 \cdot \sqrt{[0.5, 0.5] \cdot [0.5, 0.5]} = 0.707.
\end{align*}

Select Tech article (highest UCB). Observe reward $r_1 = 0.8$ (we suppress noise for clarity; in practice rewards are stochastic). Update:
\begin{align*}
  \mathbf{V}_1 &= \mathbf{V}_0 + \boldsymbol{\phi}_1 \boldsymbol{\phi}_1^\top = \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} + \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix} = \begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix}, \\
  \mathbf{b}_1 &= \mathbf{b}_0 + r_1 \boldsymbol{\phi}_1 = \mathbf{0} + 0.8 \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} 0.8 \\ 0 \end{pmatrix}, \\
  \hat{\boldsymbol{\theta}}_1 &= \mathbf{V}_1^{-1} \mathbf{b}_1 = \begin{pmatrix} 0.5 & 0 \\ 0 & 1 \end{pmatrix} \begin{pmatrix} 0.8 \\ 0 \end{pmatrix} = \begin{pmatrix} 0.4 \\ 0 \end{pmatrix}.
\end{align*}

\textbf{Round 2:} A Sports user arrives ($x_2 = \text{S}$). Compute UCBs with $\hat{\boldsymbol{\theta}}_1 = [0.4, 0]$ and $\mathbf{V}_1^{-1} = \text{diag}(0.5, 1)$:
\begin{align*}
  \text{UCB}_2(\text{Tech}) &= [0.4, 0] \cdot [0, 0.5] + \sqrt{[0, 0.5] \cdot [0.5, 1] \cdot [0, 0.5]} = 0 + \sqrt{0.25} = 0.5, \\
  \text{UCB}_2(\text{Sports}) &= [0.4, 0] \cdot [1, 0] + \sqrt{[1, 0] \cdot [0.5, 1] \cdot [1, 0]} = 0.4 + \sqrt{0.5} = 1.107, \\
  \text{UCB}_2(\text{Gen}) &= [0.4, 0] \cdot [0.5, 0.5] + \sqrt{[0.5, 0.5] \cdot [0.5, 1] \cdot [0.5, 0.5]} = 0.2 + \sqrt{0.375} = 0.812.
\end{align*}

Select Sports article. Observe $r_2 = 0.8$. Update:
\begin{align*}
  \mathbf{V}_2 &= \begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix} + \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix} = \begin{pmatrix} 3 & 0 \\ 0 & 1 \end{pmatrix}, \\
  \mathbf{b}_2 &= \begin{pmatrix} 0.8 \\ 0 \end{pmatrix} + 0.8 \begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} 1.6 \\ 0 \end{pmatrix}, \\
  \hat{\boldsymbol{\theta}}_2 &= \begin{pmatrix} 1/3 & 0 \\ 0 & 1 \end{pmatrix} \begin{pmatrix} 1.6 \\ 0 \end{pmatrix} = \begin{pmatrix} 0.533 \\ 0 \end{pmatrix}.
\end{align*}

\textbf{Round 3:} Tech user. Compute UCBs with $\hat{\boldsymbol{\theta}}_2 = [0.533, 0]$ and $\mathbf{V}_2^{-1} = \text{diag}(0.333, 1)$:
\begin{align*}
  \text{UCB}_3(\text{Tech}) &= 0.533 + \sqrt{[1, 0] \cdot [0.333, 1] \cdot [1, 0]} = 0.533 + 0.577 = 1.110, \\
  \text{UCB}_3(\text{Sports}) &= 0 + \sqrt{0.25} = 0.5, \\
  \text{UCB}_3(\text{Gen}) &= 0.267 + \sqrt{[0.5, 0.5] \cdot [0.333, 1] \cdot [0.5, 0.5]} = 0.267 + 0.659 = 0.926.
\end{align*}

Select Tech article. Observe $r_3 = 0.8$. Update:
\begin{align*}
  \mathbf{V}_3 &= \begin{pmatrix} 3 & 0 \\ 0 & 1 \end{pmatrix} + \begin{pmatrix} 1 & 0 \\ 0 & 0 \end{pmatrix} = \begin{pmatrix} 4 & 0 \\ 0 & 1 \end{pmatrix}, \quad
  \mathbf{b}_3 = \begin{pmatrix} 2.4 \\ 0 \end{pmatrix}, \quad
  \hat{\boldsymbol{\theta}}_3 = \begin{pmatrix} 0.6 \\ 0 \end{pmatrix}.
\end{align*}

\textbf{Round 4:} Sports user. With $\hat{\boldsymbol{\theta}}_3 = [0.6, 0]$ and $\mathbf{V}_3^{-1} = \text{diag}(0.25, 1)$:
\begin{align*}
  \text{UCB}_4(\text{Tech}) &= 0 + \sqrt{0.25} = 0.5, \\
  \text{UCB}_4(\text{Sports}) &= 0.6 + \sqrt{[1, 0] \cdot [0.25, 1] \cdot [1, 0]} = 0.6 + 0.5 = 1.1, \\
  \text{UCB}_4(\text{Gen}) &= 0.3 + \sqrt{[0.5, 0.5] \cdot [0.25, 1] \cdot [0.5, 0.5]} = 0.3 + 0.612 = 0.912.
\end{align*}

Select Sports article. Observe $r_4 = 0.8$:
\begin{align*}
  \mathbf{V}_4 = \begin{pmatrix} 5 & 0 \\ 0 & 1 \end{pmatrix}, \quad
  \mathbf{b}_4 = \begin{pmatrix} 3.2 \\ 0 \end{pmatrix}, \quad
  \hat{\boldsymbol{\theta}}_4 = \begin{pmatrix} 0.64 \\ 0 \end{pmatrix}.
\end{align*}

\textbf{Round 5:} Tech user. The uncertainty in the second feature dimension remains high. With $\mathbf{V}_4^{-1} = \text{diag}(0.2, 1)$:
\begin{align*}
  \text{UCB}_5(\text{Tech}) &= 0.64 + \sqrt{1 \cdot 0.2} = 1.087, \\
  \text{UCB}_5(\text{Sports}) &= 0 + \sqrt{0.5^2 \cdot 1} = 0.5, \\
  \text{UCB}_5(\text{Gen}) &= 0.32 + \sqrt{0.5^2 \cdot 0.2 + 0.5^2 \cdot 1} = 0.32 + 0.583 = 0.903.
\end{align*}

Select Tech article. Observe $r_5 = 0.8$:
\begin{align*}
  \mathbf{V}_5 = \begin{pmatrix} 6 & 0 \\ 0 & 1 \end{pmatrix}, \quad
  \mathbf{b}_5 = \begin{pmatrix} 4.0 \\ 0 \end{pmatrix}, \quad
  \hat{\boldsymbol{\theta}}_5 = \begin{pmatrix} 0.667 \\ 0 \end{pmatrix}.
\end{align*}

\textbf{Round 6:} Sports user. With $\mathbf{V}_5^{-1} = \text{diag}(0.167, 1)$:
\begin{align*}
  \text{UCB}_6(\text{Tech}) &= 0 + \sqrt{0.25} = 0.5, \\
  \text{UCB}_6(\text{Sports}) &= 0.667 + \sqrt{0.167} = 1.076, \\
  \text{UCB}_6(\text{Gen}) &= 0.333 + \sqrt{0.5^2 \cdot 0.167 + 0.5^2 \cdot 1} = 0.333 + 0.559 = 0.892.
\end{align*}

Select Sports article. Observe $r_6 = 0.8$:
\begin{align*}
  \mathbf{V}_6 = \begin{pmatrix} 7 & 0 \\ 0 & 1 \end{pmatrix}, \quad
  \mathbf{b}_6 = \begin{pmatrix} 4.8 \\ 0 \end{pmatrix}, \quad
  \hat{\boldsymbol{\theta}}_6 = \begin{pmatrix} 0.686 \\ 0 \end{pmatrix}.
\end{align*}

\textbf{Summary trace:} The following table shows the full trajectory.

\begin{center}
\begin{tabular}{cccccccc}
  $t$ & Context & $\hat{\boldsymbol{\theta}}_{t-1}$ & UCB(T) & UCB(S) & UCB(G) & Choice & Reward \\
  \hline
  1 & Tech & $[0.00,\; 0.00]$ & $1.00$ & $0.50$ & $0.71$ & Tech & $0.8$ \\
  2 & Sports & $[0.40,\; 0.00]$ & $0.50$ & $\mathbf{1.11}$ & $0.81$ & Sports & $0.8$ \\
  3 & Tech & $[0.53,\; 0.00]$ & $\mathbf{1.11}$ & $0.50$ & $0.93$ & Tech & $0.8$ \\
  4 & Sports & $[0.60,\; 0.00]$ & $0.50$ & $\mathbf{1.10}$ & $0.91$ & Sports & $0.8$ \\
  5 & Tech & $[0.64,\; 0.00]$ & $\mathbf{1.09}$ & $0.50$ & $0.90$ & Tech & $0.8$ \\
  6 & Sports & $[0.67,\; 0.00]$ & $0.50$ & $\mathbf{1.08}$ & $0.89$ & Sports & $0.8$ \\
\end{tabular}
\end{center}

\textbf{Key observations:}
\begin{itemize}
  \item \textbf{Early exploration:} At $t = 1$, all arms have high uncertainty. The algorithm selects Tech article for the Tech user because its feature vector aligns with the first coordinate (where uncertainty is initially symmetric).

  \item \textbf{Contextual learning:} By $t = 3$, the estimate $\hat{\boldsymbol{\theta}}_2 = [0.533, 0]$ correctly identifies that the first feature dimension is important (though still underestimating $\theta^*_1 = 0.8$). The algorithm consistently chooses the matched article---Tech for Tech users, Sports for Sports users---because the UCB bonus now reinforces rather than dominates the empirical estimate.

  \item \textbf{Uncertainty reduction:} The uncertainty term $\sqrt{\boldsymbol{\phi}^\top \mathbf{V}_t^{-1} \boldsymbol{\phi}}$ shrinks as data accumulates. By $t = 6$, $\mathbf{V}_6 = \text{diag}(7, 1)$ reflects seven observations involving the first feature (from Tech and Sports articles) but only one involving the second (from the ridge prior $\lambda = 1$). The algorithm has not yet explored Sports article for Tech user or Tech article for Sports user, so the second feature dimension remains unidentified ($\hat{\theta}_{6,2} = 0$).

  \item \textbf{The General article is never selected:} Even though it yields $0.6$ for both user types (better than the mismatched article's $0.2$), its UCB never exceeds that of the matched articles. This is because the matched articles benefit from both higher empirical estimates (after $t = 1$) and alignment with the estimated $\hat{\boldsymbol{\theta}}$. In a longer trace, if the algorithm were forced to explore (e.g., via decaying $\alpha$ or adversarial contexts), it would eventually discover the second feature dimension and learn $\theta_2 \approx 0.4$.

  \item \textbf{Convergence:} The estimate $\hat{\boldsymbol{\theta}}_6 = [0.686, 0]$ approaches $\theta^*_1 = 0.8$ but has not yet converged because only six observations have been made. The ridge regularization ($\lambda = 1$) biases the estimate toward zero; as $t \to \infty$, if the algorithm continues to select Tech and Sports articles in balanced proportion, $\hat{\boldsymbol{\theta}}_t$ will converge to $[0.8, 0]$ (not $[0.8, 0.4]$) because the Sports article feature $[0, 0.5]$ confounds the first and second dimensions. To fully identify $\boldsymbol{\theta}^*$, the algorithm must observe all feature directions, which may require a richer sequence of contexts or a forced-exploration policy.
\end{itemize}

This example illustrates LinUCB's ability to learn context-dependent preferences and balance exploration (via the UCB bonus) with exploitation (via the current estimate $\hat{\boldsymbol{\theta}}_t$). The algorithm is particularly effective when contexts naturally induce diversity in the feature space, allowing rapid identification of $\boldsymbol{\theta}^*$ with minimal regret.
